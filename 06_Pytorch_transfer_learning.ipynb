{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzmQVj4Zo4xGkKNtlkfIET",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEAFARI/pytorch-deeplearning/blob/main/06_Pytorch_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Transfer Learning\n",
        "\n",
        "What is transfer Learning??\n",
        "\n",
        "Transfer Learning involves taking the parameters of what one model has learned\n",
        "on another dataset and applying it to our own problem.\n",
        "\n",
        "Pretrained model = foundation model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Acwqsk-NahKP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BdeX6jM5aZNy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking the versions\n",
        "print(torch.__version__ )\n",
        "print(torchvision.__version__ )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYFyCqFjbSH9",
        "outputId": "2f2890e0-caab-4fec-ffab-9779238784f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n",
            "0.23.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "id": "k615iVSobUs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "735453b5-53ea-4c61-9483-9d807c1ac4be"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4393, done.\u001b[K\n",
            "remote: Total 4393 (delta 0), reused 0 (delta 0), pack-reused 4393 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4393/4393), 764.14 MiB | 45.75 MiB/s, done.\n",
            "Resolving deltas: 100% (2656/2656), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## setting up device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nBjrNlZH0C2h",
        "outputId": "622c7835-6b10-464d-84e4-9614f12d43ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## check gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBByeHBv0utK",
        "outputId": "1a994214-276e-4b48-e6eb-bd6970c409b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 17 12:39:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Get the data"
      ],
      "metadata": {
        "id": "ugsPswKb1TDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import data\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "## setup data path\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "## if image folder dosent exist then downlaod from github\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists. Skipping re-download....\")\n",
        "else:\n",
        "  print(f\"Couldn't find {image_path}, Downloading it....\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  ## Download from github\n",
        "  with open(data_path/\"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading pizza_steak_sushi data.... \")\n",
        "    f.write(request.content)\n",
        "\n",
        "  ## unzip pizza_steak_sushi data\n",
        "  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza steak sushi data\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "\n",
        "    ## Remove the zip file\n",
        "    os.remove(data_path/\"pizza_steak_sushi.zip\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuQFhheI04lz",
        "outputId": "dca7d6a0-b8e4-448f-ebf6-100741c17254"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couldn't find data/pizza_steak_sushi, Downloading it....\n",
            "Downloading pizza_steak_sushi data.... \n",
            "Unzipping pizza steak sushi data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## setup directory path\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GapcXCGj3WdQ",
        "outputId": "0eaf4314-3c0e-46e3-9cb4-30eae146c2f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Create Datasets and Dataloaders\n",
        "\n",
        "we'll use `data_setup.py` and the `create_dataloaders()` function created in\n",
        "going modular section\n"
      ],
      "metadata": {
        "id": "oQWQr9uuBmGL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "0db9c008-5432-4ad2-bad4-881ebe212a6c"
      },
      "source": [
        "### 2.1 Creating a transform for `torchvision.models` (manual creation)\n",
        "\n",
        "> **Note:** As of `torchvision` v0.13+, there's an update to how data transforms can be created using `torchvision.models`. I've called the previous method \"manual creation\" and the new method \"auto creation\". This notebook showcases both.\n",
        "\n",
        "When using a pretrained model, it's important that **your custom data going into the model is prepared in the same way as the original training data that went into the model**.\n",
        "\n",
        "Prior to `torchvision` v0.13+, to create a transform for a pretrained model in `torchvision.models`, the documentation stated:\n",
        "\n",
        "> All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224.\n",
        ">\n",
        "> The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]` and `std = [0.229, 0.224, 0.225]`.\n",
        ">\n",
        "> You can use the following transform to normalize:\n",
        ">\n",
        "> ```\n",
        "> normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        ">                                  std=[0.229, 0.224, 0.225])\n",
        "> ```\n",
        "\n",
        "The good news is, we can achieve the above transformations with a combination of:\n",
        "\n",
        "| **Transform number** | **Transform required** | **Code to perform transform** |\n",
        "| ----- | ----- | ----- |\n",
        "| 1 | Mini-batches of size `[batch_size, 3, height, width]` where height and width are at least 224x224^. | `torchvision.transforms.Resize()` to resize images into `[3, 224, 224]`^ and `torch.utils.data.DataLoader()` to create batches of images. |\n",
        "| 2 | Values between 0 & 1. | `torchvision.transforms.ToTensor()` |\n",
        "| 3 | A mean of `[0.485, 0.456, 0.406]` (values across each colour channel). | `torchvision.transforms.Normalize(mean=...)` to adjust the mean of our images.  |\n",
        "| 4 | A standard deviation of `[0.229, 0.224, 0.225]` (values across each colour channel). | `torchvision.transforms.Normalize(std=...)` to adjust the standard deviation of our images.  |\n",
        "\n",
        "> **Note:** some pretrained models from `torchvision.models` in different sizes to `[3, 224, 224]`, for example, some might take them in `[3, 240, 240]`. For specific input image sizes, see the documentation.\n",
        "\n",
        "> **Question:** *Where did the mean and standard deviation values come from? Why do we need to do this?*\n",
        ">\n",
        "> These were calculated from the data. Specifically, the ImageNet dataset by taking the means and standard deviations across a subset of images.\n",
        ">\n",
        "> We also don't *need* to do this. Neural networks are usually quite capable of figuring out appropriate data distributions (they'll calculate where the mean and standard deviations need to be on their own) but setting them at the start can help our networks achieve better performance quicker.\n",
        "\n",
        "Let's compose a series of `torchvision.transforms` to perform the above steps."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Create a transforms pipeline manually (required for torchvision < 0.13)\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ],
      "metadata": {
        "id": "MVeza-IkD_32"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Create Datasets and Dataloaders\n",
        "\n",
        "from going_modular.going_modular import data_setup\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=manual_transforms,\n",
        "                                                                               batch_size=32)"
      ],
      "metadata": {
        "id": "3trGZZCr4HFz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7HFaYQNE65s",
        "outputId": "2bbbd1c2-26d5-4932-bbc7-67c800e78293"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pizza', 'steak', 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdk-T5LeEaHV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}